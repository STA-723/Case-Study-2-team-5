---
title: "Regression Modeling"
author: "Youngsoo Baek"
date: "\\today"
---

Trying out a reasonable regression model (right now univariate, with response `price`). Ideally, we should be able to address heterogeneity in the types of listing across both neighbourhood (finer) and borough (coarser) scales. The most straightforward way to do this that I can think of is a multilevel modeling as implemented in `stanarm`. When regressing one on another, we scale the price and monthly reviews to log scale, as the dataset exhibits clear inverse relatinoship between the two.

# Before fitting

```{r prep, echo=F, include=F, message=F, warning=F}
library(dplyr)
library(ggplot2)
library(lubridate)
options(mc.cores = parallel::detectCores())
airbnb <- read.csv("./AB_NYC_2019.csv")
airbnb[airbnb$price==0, "price"] <- 5 # All imputed by 10/2
airbnb$minimum_nights <- ifelse(airbnb$minimum_nights > 365, 365, airbnb$minimum_nights)

data <- airbnb[airbnb$number_of_reviews != 0,] # Exclude zero reviews
# Logarithmic scale (where rel. is actually linear)
data <- data %>% 
    filter(availability_365 != 0) %>% # Simply exclude for now 
    mutate(price = log(price), 
                reviews_per_month = log(reviews_per_month),
                last_review = year(ymd(last_review)))
```


  i. For log transformation of price and the monthly number of reviews, here I have excluded any listings that do not have any reviews (roughly `r round(sum(airbnb$number_of_reviews==0)/nrow(airbnb) * 100, 0)`\%).
  
  ii. Housings with zero price are considerd as having a nightly price of <\$10, and imputed \$5. There are only few such listings, so the analysis should be quite insensitive to our choice of action.
  
  iii. The year in which the last review was left is included in the model as a possible predictor.
  
  iv. There are `r sum(airbnb$minimum_nights > 100)` listings that specify minimum nights of stay for more than 100 days, and among them very few have minimum nights of more than a year. I believe those listings with minimum stay of more than 365 days are likely to be measurement errors and truncate them at 365.
  
  v. After excluding listings with no reviews, there still exist `r sum(airbnb[airbnb$number_of_reviews!=0,]$availability_365==0)` listings that say they are not available in any day at all. Based on the more or less even distribution of this variable, I believe these listings simply did not choose to specify this variable. I have not yet chosen what to do with these listings, so I have simply excluded them in the model fit stage below. Imputing a single value means I am drastically changing the distribution of this underlying predictor, for which I have a strong prior belief that it is uniform.

# Fitting the  Model
All of the above steps imply that we have reduced the sample size down to `r round(nrow(data)/nrow(airbnb), 0)`\% of the original data. Still, we have a moderately large dataset for Bayesian model fitting, and computation can be difficult for even a simple multilevel model. As a preliminary step, we can quite easily fit through MLE two models: one with neighbourhood random effect only, and another with neighbourhood-effect nested within each borough. There does not seem to be a significant change in most of the estimated coefficients, and it does seem that our mixed effects model is already doing quite well.

```{r mle}
library(lme4)
# 1. Neighbourhood-varying intercept
mod1 <- lmer(price ~ 1 + reviews_per_month + room_type + minimum_nights + 
         last_review + calculated_host_listings_count + availability_365 + 
         (1|neighbourhood), data = data)
# 2. Borough-varying + Neighbourhood-varying w/in Borough
mod2 <- lmer(price ~ 1 + reviews_per_month + room_type + minimum_nights + 
               last_review + calculated_host_listings_count + availability_365 + 
               (1|neighbourhood_group/neighbourhood), data = data)
knitr::kable(summary(mod1)$coefficients, caption = "Neighbourhood-varing intercept", digits = 2)
knitr::kable(summary(mod2)$coefficients, caption = "Borough/Neighbourhood-varying intercept", digits = 2)
```

Ideally, I want to also fit a model that has varying slopes for few select variables. Specifically, I believe there can be different effects for the host's listing counts, as the `summary(mod2)` call shows that the significance of this variable is gone when we are conditioning on the borough's effect. Estimating this is difficult through MLE, however, as Bronx and Staten Island have too few observations relative to the three others. 

# Non-evidence of spatial correlation
If there were some minute-scale spatial correlation between these observations unaccounted for by the model (i.e., within neighbourhood), the **semivariogram estimates** (see: https://en.wikipedia.org/wiki/Variogram) calculated from the residuals of the above model should display a clear pattern when plotted against pairwise distances. This does not seem to be the case; semivariograms look more or less constant in increasing pairwise distance, so it seems unwarranted that we overfit the model after conditioning on neighbourhood and borough effects. I would rather instead focus now on whether a Bayesian model fit returns different estimates, some sensitivity analyses, and the joint modeling of price and popularity variables as in below.

```{r semivariogram, cache=T}
library(geoR)
empirical_vs <- variog(coords = data[,c("longitude", "latitude")],
                       data = resid(mod2))
plot(empirical_vs) # In distance, the residuals are stable
```

# Bivariate outcome regression
I want to try the following model: ordering the 1st response as price and 2nd response as monthly number of reviews (both on log-scale), we expect them to have a rather strong negative linear correlation from the EDA. A multivariate normal regression model would be:
$$
\left(\begin{array}{c}
Y_{1,i}\\ Y_{2,i} \end{array}\right) \stackrel{iid}{\sim} {\rm N}\left(
\left(\begin{array}{c}
\beta_1^T\mathbf{X}_i^T \\
\beta_2^T\mathbf{X}_i^T
\end{array}\right),
\left(\begin{array}{cc}
\sigma_1^2 & \rho\sigma_1\sigma_2\\
\rho\sigma_1\sigma_2 & \sigma_2^2
\end{array}\right)
\right),\; i=1,2,\ldots,n.
$$
We have strong prior belief that $\rho\in (-1,0)$; however, I haven't found yet a good way to make the prior distribution on the covariance to reflect this.

I have looked up a few packages for implementing this, and concluded that I will just use a stan code to fit this model, since I ideally want to expand this to include the random effects above anyways. Of course, this model may take forever to fit / have convergence issues in the MCMC -- I haven't tried it yet. Note that Stan does not use Gibbs, so the choice of priors may look a bit wonky (but they are actually recommended by the authors of the program).

```{r}
library(rstan)
writeLines(readLines("./bv_regression.stan"))
# Dummy here; not actually run
# I have checked the sampler does run for a few iterations!
# Now want to check how long it takes to fit this model
# stan(file = "bv_regression.stan",
#      data = list(
#        N = nrow(data), P = 11,
#        x = model.matrix(price ~ room_type + minimum_nights + last_review + 
#                           calculated_host_listings_count + availability_365 + 
#                           neighbourhood_group, 
#                         data = data),
#        y = as.matrix(data[,c("price", "reviews_per_month")])
#      ),
#     chains = 1 , iter = 10)
```

Alternatively, using `lme4` in a hacky way to just maximize the likelihood (code idea from https://mac-theobio.github.io/QMEE/MultivariateMixed.html):

```{r}
# Dataset must be modified to "trick" lme4
data_mv <- data %>% select(price, reviews_per_month) %>% 
  reshape2::melt()
data_mv <- cbind.data.frame(data_mv, (data %>% select(-price, -reviews_per_month)))
# Use the "long format" dataset and put variable label as a predictor
mod3 <- lmer(value ~ variable:(1+room_type+minimum_nights+last_review+
                                 calculated_host_listings_count+availability_365)+
               (variable-1|neighbourhood_group/neighbourhood) + 
               (variable-1|neighbourhood_group), 
             data = data_mv,
             control = lmerControl(optCtrl = list(ftol_abs = 1e-10)))
```

COME BACK: Above code causes error. Make sure I have put the predictors on similar scale, and consider what numerical issues I'm having. I still have enough time to use Stan.
